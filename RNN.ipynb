{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMgYslOCfzMLNyaE3UFjSYR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShrivastavAbhishek2004/AIML_Training/blob/main/RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import SimpleRNN, Input, Dense, Embedding\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "metadata": {
        "id": "xc_R8PNp1OQ0"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "Qkr-sTLywtkn"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import Sequential\n",
        "import tensorflow as tf\n",
        "#Samle text data\n",
        "data = [\"I love programming\",\n",
        "        \"Programming is fun\",\n",
        "        \"Deep learning is powerful\",\n",
        "        \"I love deep learning\"]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Tokenizer and Sequence data\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(data)\n",
        "sequences = tokenizer.texts_to_sequences(data)"
      ],
      "metadata": {
        "id": "k_KpyJSc1W_D"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Prepare input and outputs for RNN\n",
        "input_size = len(tokenizer.word_index) + 1\n",
        "input_sequences = []\n",
        "for sequence in sequences:\n",
        "    for i in range(1, len(sequence)):\n",
        "        input_sequences.append(sequence[:i+1])"
      ],
      "metadata": {
        "id": "1O21kpxd0uG_"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#pad sequences\n",
        "max_length = max([len(seq) for seq in input_sequences])\n",
        "padded_sequences = pad_sequences(input_sequences, maxlen=max_length, padding='pre')"
      ],
      "metadata": {
        "id": "OslwcVq-1UGH"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#split input X and y target\n",
        "\n",
        "X = input_sequences[:, :-1]\n",
        "y = input_sequences[:, -1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "VZmJ94EX2Ova",
        "outputId": "9b661092-3637-4ffc-f045-db0a5cb4d21d"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "list indices must be integers or slices, not tuple",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-a423077d4f87>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#split input X and y target\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_sequences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_sequences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not tuple"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Build RNN model\n",
        "model = Sequential([\n",
        "    Embedding(vocab_size, 10, input_length=X.shape[1]),\n",
        "    SimpleRNN(50, activation='tanh'),\n",
        "    Dense(vocab_size, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "lUY6lsAD2_fa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#compile the model\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "eHQ5Pngh4CV3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Train the model\n",
        "model.fit(X, y, epochs=100, verbose=1)"
      ],
      "metadata": {
        "id": "3D2H-5p74Jnk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Test the model\n",
        "input_text = \"I love deep\"\n",
        "tokenized_input = tokenizer.texts_to_sequences([input_text])[0]\n",
        "tokenized_input = pad_sequences([tokenized_input], maxlen=max_length - 1, padding='pre')\n",
        "predicted_sequence = model.predict(input_sequence)\n",
        "predicted_word = tokenizer.index_word[np.argmax(predicted_sequence)]"
      ],
      "metadata": {
        "id": "XV7NAvIn4mFq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}